  config = 'Hourly'
  model = DeployedESTransformer(max_epochs = 500,
                                batch_size = config['train_parameters']['batch_size'],
                                freq_of_test = config['train_parameters']['freq_of_test'],
                                learning_rate = float(config['train_parameters']['learning_rate']),

                                per_series_lr_multip = config['train_parameters']['per_series_lr_multip'],
                                lr_scheduler_step_size = config['train_parameters']['lr_scheduler_step_size'],
                                lr_decay = config['train_parameters']['lr_decay'],

                                transformer_weight_decay = 0.0,

                                level_variability_penalty = config['train_parameters']['level_variability_penalty'],
                                
                                testing_percentile = config['train_parameters']['testing_percentile'],
                                training_percentile = config['train_parameters']['training_percentile'],
                                
                                ensemble = config['train_parameters']['ensemble'], ####################
                                seasonality = config['data_parameters']['seasonality'],
                                
                                random_seed = config['model_parameters']['random_seed'],
                                device= config['device'],
                                root_dir= args.results_directory,

                                # Semi-hyperparameters
                                input_size = config['data_parameters']['input_size'],
                                d_input = config['data_parameters']['d_input'], # input_size + 6 (which is exo features)
                                output_size = config['data_parameters']['output_size'], # must be the same as d_output
                                d_output = config['data_parameters']['d_output'], # input_size + output_size >= 13
                                
                                # Worth tuning hyperparameters
                                d_model = 128,
                                q = 4,
                                v = 4,
                                h = 4,
                                N = 2,
                                attention_size = 4,
                                dropout = 0,
                                chunk_mode = None, ####################
                                pe = None, ####################
                                pe_period = 24,
                                dataset_name = args.dataset) ####################